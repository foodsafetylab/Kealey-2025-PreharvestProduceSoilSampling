---
title: "Prevalence filtering"
execute:
  echo: false
  message: false
  warning: false
---

```{r, include=FALSE}
# Load functions in "common_code.R"
# at some point this should be moved into bookdown
source("src/common_code.R", local = knitr::knit_global())
```

```{r}
physeq.filtered <- readRDS('results/physeq.filtered.RDS')
# metadata<-readRDS("results/metadata.RDS")
```

For beta diversity, we perform initial prevalence filtering and agglomeration (either tip or taxonomic rank-based). Tip-based is recommended for PacBio or other long-read technologies, while taxonomic rank-based is recommended for standard short-read Illumina sequencing.

## Additional Filtering

We performed some high level filtering to remove artifacts and problematic data. Next step is agglomeration of count data and prevalence filtering.

## Explore taxon data

What is the range in total counts per taxon?

```{r PrevalenceFiltering-8 }
range(taxa_sums(physeq.filtered))
```

Some taxa with very low counts overall; depending on their prevalence this may be removed. What does the distribution look like at the low end?

```{r PrevalenceFiltering-9 }
hist(log2(taxa_sums(physeq.filtered)), 1000)
```

There are a few at the low end.

What about `sample_sums`? What is the range in total counts per sample?

```{r PrevalenceFiltering-10 }
range(sample_sums(physeq.filtered))
```

We have some at the low end, with `r sum(sample_sums(physeq.filtered) <= 5000)` sample(s) less than 5k counts. We seem to have higher number of reads for Booties and Grabs than Drags.

```{r PrevalenceFiltering-11 }

df <- data.frame(
    SampleSums = sample_sums(physeq.filtered),
    Names = factor(sample_data(physeq.filtered)$Label, ordered = TRUE,
                   ),
    Group = factor(sample_data(physeq.filtered)$group, ordered = TRUE))

df$Group <- factor(df$Group, levels = c("Drags_PBS", "Drags_BPW", "Booties_PBS","Booties_BPW","Grabs_N/A"))

p <- ggplot(data = df, aes(y = SampleSums, x = Names, fill = Group))+
   scale_fill_manual(values = dittoSeq::dittoColors()[1:100]) +
  ylab("Total read count per sample")+
  xlab("Groups")+geom_bar(stat = 'identity') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
  
p$data$Group <- factor(p$data$Group,levels = c("Drags_PBS", "Drags_BPW", "Booties_PBS","Booties_BPW","Grabs_N/A"))

p$data$Names <- factor(p$data$Names,levels = c(
  "Drags_PBS_Beets",
  "Drags_PBS_Leafy Greens",
  "Drags_PBS_Peppers",
  "Drags_PBS_Apples",
  "Drags_PBS_Melons",
  
  "Drags_BPW_Beets",
  "Drags_BPW_Leafy Greens",
  "Drags_BPW_Peppers",
  "Drags_BPW_Apples",
  "Drags_BPW_Melons",
  
  "Booties_PBS_Beets",
  "Booties_PBS_Leafy Greens",
  "Booties_PBS_Peppers",
  "Booties_PBS_Apples",
  "Booties_PBS_Melons",
  
  "Booties_BPW_Beets",
  "Booties_BPW_Leafy Greens",
  "Booties_BPW_Peppers",
  "Booties_BPW_Apples",
  "Booties_BPW_Melons",
  
  "Grabs_N/A_Beets",
  "Grabs_N/A_Leafy Greens",
  "Grabs_N/A_Peppers",
  "Grabs_N/A_Apples",
  "Grabs_N/A_Melons"))


ggplotly(p)
```

How do the ASV counts correlate with the read counts? (is higher number of reads correlated with higher number of ASVs?)

These do not correlate only slightly with the read counts.

```{r PrevalenceFiltering-12, echo=FALSE, message=FALSE}
myData <- data.frame(
  Name = sample_data(physeq.filtered)$Label,
  OTUSums = sample_sums(physeq.filtered),
  Reads = as.numeric(sample_data(physeq.filtered)$input),
  Group = sample_data(physeq.filtered)$group
)
p <- ggplot(data = myData, aes(x = Reads, y = OTUSums)) + 
  #geom_smooth(method = "gam", color = "lightgreen") + 
  geom_smooth(method = "lm", color = "lightblue") + 
  geom_point(aes(color = Group))
ggplotly(p)
```



<!-- We will skip tip agglomeration in favor of taxa agglomeration. But first let's do prevalence filtering. -->

<!-- ### Tip agglomeration -->

<!-- What does the current tree look like? -->

<!-- ```{r PrevalenceFiltering-13} -->

<!-- p <- plot_tree(physeq.filtered,  -->

<!--           nodelabf = nodeplotblank,  -->

<!--           color="Sample",  -->

<!--           ladderize = "left",  -->

<!--           method = "treeonly") + -->

<!--   ggtitle(paste0("Original tree: ", ntaxa(physeq.filtered), " taxa")) + -->

<!--   theme(plot.title = element_text(size = 10)) -->

<!-- ggplotly(p) -->

<!-- ``` -->

<!-- Zooming into the tips indicates there are a many sequences with very small differences. -->

<!-- ```{r PrevalenceFiltering-14} -->

<!-- hist(log(phy_tree(physeq.filtered)$edge.length),  -->

<!--      xlab = "Edge Length (log)",  -->

<!--      main = "Edge length distribution") -->

<!-- ``` -->

<!-- #### Clip out long branches -->

<!-- There may be one longer branch to check, but overall doesn't look bad. You have to zoom into the right a bit and look at the frequencies accordingly: -->

<!-- ```{r PrevalenceFiltering-14.B} -->

<!-- tmp <- phy_tree(physeq.filtered) -->

<!-- # grab the tip lengths and format for ggplot -->

<!-- treeTips <- data.frame( -->

<!--   ID = tmp$tip.label, -->

<!--   Tip.Length = tmp$edge.length[tmp$edge[,2] <= Ntip(tmp)] -->

<!-- ) -->

<!-- p <- treeTips %>% -->

<!--   ggplot( aes(x=Tip.Length, fill = "black")) + -->

<!--   geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity', bins = 100) -->

<!-- ggplotly(p + xlim(0.1, 1) + ylim(0,10)) -->

<!-- ``` -->

<!-- A couple stand out with very long tip lengths. What are the first 5? -->

<!-- ```{r} -->

<!-- longbranch <- treeTips[order(treeTips$Tip.Length, decreasing = TRUE)[1:5],] -->

<!-- tmp2 <- cbind(tax_table(physeq.filtered), as.data.frame(taxa_sums(physeq.filtered))) -->

<!-- knitr::kable(tmp2[longbranch$ID,]) -->

<!-- ``` -->

<!-- The longest branch looks real and is very prevalent so I don't see any need to remove long branches. -->

<!-- What samples are these in? -->

<!-- ```{r} -->

<!-- tmp <-suppressWarnings(prune_taxa(taxa_names(physeq.filtered) %in% longbranch$ID, -->

<!--                   physeq.filtered)) -->

<!-- ssums <- sample_sums(tmp) -->

<!-- ssums[ssums > 0] -->

<!-- ``` -->

<!-- They are spread across samples as well. -->

<!-- ### Plot cophenetic distances -->

<!-- Agglomeration is based on the cophenetic distance, the pairwise distances between tips on the tree. These are pretty short; let's see what that distribution looks like -->

<!-- ```{r PrevalenceFiltering-15} -->

<!-- cp_phylo <- cophenetic.phylo(phy_tree(physeq.filtered)) -->

<!-- hist(cp_phylo,  -->

<!--      breaks = 100,  -->

<!--      main = "Pairwise distance between tips",  -->

<!--      xlab = "Distance between tips") -->

<!-- cutoff <- c(seq(0.025, 0.15, 0.025), 0.2, 0.3, 0.5, 0.75, 1, 2) -->

<!-- abline(v=cutoff, col = "red") -->

<!-- text(cutoff, max(hist(cp_phylo, 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 ) -->

<!-- ``` -->

<!-- Note those at the high end of distance, probably out off-shoot group. We do not see those in the merged data! -->

<!-- The red lines are some arbitrary test cutoffs. Based on the above we could use 0.05 (right after first peak from left) or even between 0.15 and 0.2 (right after the second small peak from the left). -->

<!-- Let's replot in log scale.   -->

<!-- ```{r PrevalenceFiltering-16} -->

<!-- hist(log(cp_phylo),  -->

<!--      breaks = 100,  -->

<!--      main = "Pairwise distance between tips",  -->

<!--      xlab = "Distance between tips (log)",  -->

<!--      xlim = c(-5, 5)) -->

<!-- abline(v=log(cutoff), col = "red") -->

<!-- text(log(cutoff), max(hist(log(cp_phylo), 100, plot=FALSE)$counts), labels = cutoff, pos = 2, srt = 90, cex = .5 ) -->

<!-- ``` -->

<!-- The log scale doesn't make the cutoff any clearer, so lets explore more. -->

<!-- ```{r PrevalenceFiltering-17} -->

<!-- # Use the cutoffs listed above -->

<!-- # this takes some time to run :).  There is a speedyseq package with a faster tip_glom implementation, might be worth checking -->

<!-- pseqs <- lapply(cutoff[1:7], function(x) {tip_glom(physeq.filtered, h = x)}) -->

<!-- names(pseqs) <- cutoff[1:7] -->

<!-- ``` -->

<!-- ```{r PrevalenceFiltering-18} -->

<!-- # In order to screen for instances with a tree we need to use tryCatch as checking the tree slot with phy_tree will error if it is NULL) -->

<!-- pseqs.final <- pseqs[sapply(pseqs, function(x) { -->

<!--   !is.null( tryCatch({phy_tree(x)}, error = function(cond) { return(NULL) }) ) -->

<!--   }, simplify = TRUE)] -->

<!-- plots <- sapply(names(pseqs.final), function(x) { -->

<!--   plot_tree(pseqs.final[[x]],  -->

<!--           nodelabf = nodeplotblank, -->

<!--           ladderize = "left",  -->

<!--           method = "treeonly") +  -->

<!--   ggtitle(paste0("Height:",x, ", ", ntaxa(pseqs.final[[x]]), " taxa")) +  -->

<!--     theme(plot.title = element_text(size = 10)) -->

<!--   }, simplify = FALSE -->

<!--   ) -->

<!-- grid.arrange(grobs = prepend(plots, list(Original = p)), -->

<!--              nrow = 3) -->

<!-- ``` -->

<!-- Still seeing small branches in height of 0.05. Let's try 0.175 (where the second small peak ended). -->

<!-- ```{r PrevalenceFiltering-22} -->

<!-- # pseqs <- lapply(cutoff[1:8], function(x) {speedyseq::tip_glom(physeq.filtered, h = x)}) -->

<!-- physeq.glom <- tip_glom(physeq.filtered, h = 0.175) -->

<!-- physeq.glom -->

<!-- ``` -->

## Prevalence filtering

For the filtering, let's take a look at our data and see how many features are present per taxa.

<!-- let's assign the original filtered data to a temp variable prior to prevalence filtering. -->

```{r PrevalenceFiltering-26 }
#physeq0 <- physeq.glom
physeq0 <- physeq.filtered
physeq0
```

<!-- Suggested based on the Callahan dada2 workflow (F1000Research, 2017).  -->


```{r PrevalenceFiltering-27 }
table(tax_table(physeq0)[,"Phylum"], exclude = NULL)

df = data.frame(table(tax_table(physeq0)[,"Phylum"])) %>% setNames(c("Domain", "Count"))
df.low = df[df$Count < 5 ,]

```

There are `r nrow(df.low)` taxa with low features (1-4 OTUs). No NA's present, so don't need to filter NAs. Now, let's get an idea of prevalence, or how many samples each ASV is present in. We can make this more or less strict as needed, but for now we're only including ASVs that are present in at least 1 sample.

```{r PrevalenceFiltering-29 }
# What is this doing?  It calculates a vector with the count being the # samples with a count > 0.

# Note: make sure you are using *raw counts* here; if you use proportional
# counts make sure to adjust the function appropriately
prevdf <- apply(otu_table(physeq0),  # counts
               # use row or column depending on the data
               MARGIN = ifelse(taxa_are_rows(physeq0), yes = 1, no = 2), 
               # how many times the counts in the samples are greater than 0
               FUN = function(x){sum(x > 0)}  
               )
prevdf <- data.frame(Prevalence =  prevdf, # num samples counts are > 0
                     TotalAbundance = taxa_sums(physeq0), # total abundance
                     tax_table(physeq0)) # tax ID and ranks
```

```{r}
# a quick high level summary at the Phylum rank.
tmp <- plyr::ddply(prevdf, "Phylum", function(df1) { cbind(mean(df1$Prevalence), sum(df1$Prevalence)) })
colnames(tmp) <- c("Phylum", "mean", "sum")
tmp <- tmp[order(tmp$sum, decreasing = TRUE),]
rownames(tmp) <- NULL
```

Here is a quick summary of the prevalence results. These are performed per ASV but summarized at the Phylum rank. For example, the mean number of samples each `r tmp$Phylum[1]` ASV is present in `r tmp$mean[1]` and the sum of all these prevalence counts is `r format(tmp$sum[1], scientific=F)`.

```{r PrevalenceFiltering-30 }
knitr::kable(tmp)
```


```{r PrevalenceFiltering-31}
#subset <- subset_samples(physeq.filtered, Specimen !="NegativeControl")
df2 <- sample_data(physeq.filtered) %>% data.frame() %>% dplyr::count(group)
#df2 <- sample_data(physeq.filtered) %>% data.frame() %>% dplyr::count(Sample_Type)

#prevThreshold <- min(df2$n)
prevThreshold <- 10
#pthresh <- 0.05

pthresh <- prevThreshold / nsamples(physeq.filtered) 

#(prevThreshold <- pthresh * nsamples(physeq.filtered))
```

<br>

The top four most prevalent are `r tmp$Phylum[1]`, `r tmp$Phylum[2]`, `r tmp$Phylum[3]` and `r tmp$Phylum[4]`. We can plot these out to get more resolution. Let's graph the prevalence threshold using `r round(pthresh, digits=2)`. This is around `r round(pthresh * nsamples(physeq0))` samples. We can modify this setting, but we'll leave as is for now. The following plot shows the fraction of samples vs the total abundance for that, which helps give some idea on what to retain.

```{r PrevalenceFiltering-32}
ggplot(prevdf,
       aes(TotalAbundance, Prevalence / nsamples(physeq0), color = Phylum)) +
  geom_hline(yintercept = pthresh, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.4) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position = "none")
   #scale_color_manual(values = dittoSeq::dittoColors()[1:9])
```

The horizontal line indicates the cutoff in this case. Let's apply it and see what happens.

```{r PrevalenceFiltering-33 }

keepTaxa <- rownames(prevdf)[(prevdf$Prevalence >= prevThreshold)]
#physeq.prev <- prune_taxa(keepTaxa, physeq.glom)
physeq.prev <- prune_taxa(keepTaxa, physeq.filtered)

```

This keeps `r round(nrow(tax_table(physeq.prev)) / nrow(tax_table(physeq.filtered)) * 100)` percent of the original number of taxa. How does this affect counts?

```{r PrevalenceFiltering-34, fig.width=12}
physeq.prev
df <- data.frame(
    #SampleLoss = sample_sums(physeq.prev) / sample_sums(physeq.glom),
    Reads_Retained = sample_sums(physeq.prev) / sample_sums(physeq.filtered),
    Names = factor(sample_data(physeq.prev)$Label, ordered = TRUE, levels = unique(sample_data(physeq.prev)$Label)),
    Group = factor(sample_data(physeq.prev)$group, ordered = TRUE),
    SampleID = factor(sample_data(physeq.prev)$Sample_ID, ordered = TRUE)
)

#df$Group <- factor(df$Group,levels = c("Ctrl_D0","Ctrl_D19","Ctrl_D1016",
                                     #  "NonPolar_D19", "NonPolar_D1016",
                                      # "Polar_D19", "Polar_D1016"))

# df$Names <- factor(df$Names,levels = c("Ctrl_D0_Donor1","Ctrl_D0_Donor2", "Ctrl_D0_Donor3",
#                                        "Ctrl_D19_Donor1","Ctrl_D19_Donor2","Ctrl_D19_Donor3",
#                                        "Ctrl_D1016_Donor1","Ctrl_D1016_Donor2","Ctrl_D1016_Donor3",
#                                        "NonPolar_D19_Donor1","NonPolar_D19_Donor2","NonPolar_D19_Donor3","NonPolar_D1016_Donor1",
#                                        "NonPolar_D1016_Donor2","NonPolar_D1016_Donor3",
#                                        "Polar_D19_Donor1", "Polar_D19_Donor2",
#                                        "Polar_D19_Donor3", "Polar_D1016_Donor1",
#                                        "Polar_D1016_Donor2","Polar_D1016_Donor3"))

df <- df %>%
   arrange(Group,SampleID)

# df$SampleID <- factor(df$SampleID, levels = c("M1_D0","M2_D0","M3_D0", "M1_C7","M1_C8",
#                           "M1_C9","M2_C7","M2_C8","M2_C9","M3_C7",
#                           "M3_C8","M3_C9","M1_C15","M1_C16","M2_C14",
#                           "M2_C15", "M2_C16", "M3_C14", "M3_C15", 
#                           "M3_C16", "M1_NP7", "M1_NP8", "M1_NP9", 
#                           "M2_NP7", "M2_NP8","M2_NP9","M3_NP7","M3_NP8",
#                           "M3_NP9", "M1_NP14", "M1_NP15", "M1_NP16",
#                           "M2_NP14", "M2_NP15", "M2_NP16", "M3_NP14",
#                           "M3_NP15", "M3_NP16", "M1_P7","M1_P8","M1_P9",
#                           "M2_P7","M2_P8","M2_P9","M3_P7","M3_P8","M3_P9",
#                           "M1_P14","M1_P15","M1_P16","M2_P14","M2_P15","M2_P16",
#                           "M3_P14","M3_P15" ,"M3_P16")) 

#df %>% mutate(name=factor(SampleID, levels=SampleID))

p <- ggplot(data = df, aes(x = SampleID, y = Reads_Retained, fill = Group))

p$data$Group <- factor(p$data$Group,levels = c(
                  "Drags_PBS",
                   "Drags_BPW",
                   "Booties_PBS",
                   "Booties_BPW", 
                   "Grabs_N/A"))

p + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = scales::percent) +
   scale_x_discrete(limits = levels(df$SampleID))


```

We are not loosing a lot for most samples. The lowest loss is related to `r subset(df, Reads_Retained == max(df$Reads_Retained))$SampleID` with `r round(max(df$Reads_Retained), digits=4)*100`% of reads maintained and highest loss is related to `r subset(df, Reads_Retained == min(df$Reads_Retained))$SampleID` with `r round(min(df$Reads_Retained), digits=4)*100`% of reads retained.

## Taxa agglomeration

Phyloseq's tax_glom method is analogous to it's tip_glom method, but it uses categorical data instead of tree data to agglomerate.

What is the effect of taxonomic agglomeration per rank if we were to allow for the removal of NA's? If we don't allow NA's to be removed, then we lose nothing. They just get grouped to the next available ranking. I would not recommend removing NA's as it could skew beta diversity measurements downstream, but it is interesting to see how many sequences are ranked to each level.

What is the effect of taxonomic agglomeration per rank? Let's do a quick run through on the samples; ranks that are not assigned are removed by default, so let's see what happens.

```{r PrevalenceFiltering-23 }
taxglom_per_rank = function(physeq.prev, rank = "Species") {
  # TODO: add sanity check
  glommedPhyseq <- tax_glom(physeq.prev, taxrank = rank, NArm = TRUE)
  p <- ggplot(data = data.frame(
      Reads_Retained = sample_sums(glommedPhyseq) / sample_sums(physeq.filtered),
      Names = factor(sample_data(glommedPhyseq)$Label,
                     ordered = TRUE,
                     levels = unique(sample_data(glommedPhyseq)$Label)),
      Group = factor(sample_data(glommedPhyseq)$SampleID, ordered = TRUE),
      SampleID = factor(sample_data(physeq.prev)$SampleID, ordered = TRUE)
  ), aes(y = Reads_Retained, x = SampleID, fill = Group)) +
    geom_bar(stat = 'identity' ) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle(paste0("Rank: ", rank))
  return(p)
}
```

```{r PrevalenceFiltering-24 }
tmp <- as(tax_table(physeq.prev), 'matrix')
tmp[tmp == 'Unclassified'] = NA
tax_table(physeq.prev) <- tmp
```

```{r, fig.height=8, fig.width=14 }
ranks <- c("Species", "Genus", "Family", "Order")

plots <- lapply(ranks, function(x) {
  p <- taxglom_per_rank(physeq.prev, rank = x)
  p + theme(legend.position = "none") + expand_limits(y = c(0, 1))
})

grid.arrange(grobs = plots)
```

Quite a bit lost with most ranks.

Are there rows in there with 'NA'?

```{r PrevalenceFiltering-25 }
#apply(tax_table(physeq.filtered), 2, function(x) sum(x != "Unclassified"))
apply(tax_table(physeq.prev), 2, function(x) sum(is.na(x)))
```


Let's save the filtered file for later use.

```{r PrevalenceFiltering}
saveRDS(physeq.prev, file = "results/phyloseq.prevfiltered.notglommed.RDS")
```

A steep increase in unassigned ranks from Family to Genus. Let's use Family level for taxa agglomeration in `tax_glom()` package in phyloseq.


```{r}
 physeq.glom <- tax_glom(physeq.prev, taxrank = 'Family', NArm = FALSE)

```

<!-- Yes, though not nearly as many as the overall # of taxa. This suggests maybe using the phylogenetic tree and `tip_glom`. We have been seeing this work with better fidelity with more recent data sets, particularly from PacBio sequences, but it does require a little checking on the phylogenetic branch lengths to determine the best cutoff. The code below is based on work Lindsay Clark and Jenny have done in the group.  -->

<!-- ## Tree glom  -->

<!-- This is a newer but somewhat experimental method implemented in the `speedyseq` package. -->

<!-- ```{r} -->

<!-- #get_pairwise_distances(tree, A, B, as_edge_counts=FALSE, check_input=TRUE) -->

<!-- ``` -->

Here is what the phyloseq object looks like after agglomeration. We have `r nrow(tax_table(physeq.glom))`  taxa at the Family level.

```{r}
 physeq.glom
```

<!-- `r ncol(otu_table(physeq.glom))` ASVs/features are retained. -->

```{r PrevalenceFiltering-35 }
saveRDS(physeq.glom, file = "results/phyloseq.prevfiltered.RDS")
```
